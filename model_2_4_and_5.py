# -*- coding: utf-8 -*-
"""model-2-4-and-5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/iatskin/e77ac12bd61bb35c6293b6a19917f91f/model-2-4-and-5.ipynb
"""

!pip install torch numpy datasets transformers scikit-learn

pip install --upgrade transformers

#Model 2
import torch
import pandas as pd
import numpy as np
from datasets import Dataset, ClassLabel
from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt

#Load CSV
df = pd.read_csv("toxigen.csv")
df = df[df['prompt_label'] == 1].reset_index(drop=True)
#Categories in ind
labels = list(df["group"].unique())
label2id = {label: i for i, label in enumerate(labels)}
id2label = {i: label for label, i in label2id.items()}
df["label"] = df["group"].map(label2id)

#Class weights
class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(df["label"]), y=df["label"])
class_weights = torch.tensor(class_weights, dtype=torch.float32).to("cuda")

#Convert to Dataset
dataset = Dataset.from_pandas(df)
dataset = dataset.cast_column("label", ClassLabel(num_classes=len(labels)))

#Tokenezier and model
model_name = "roberta-base"
tokenizer = RobertaTokenizer.from_pretrained(model_name)
model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))

#Token
def tokenize_function(example):
    return tokenizer(example["generation"], truncation=True, padding="max_length", max_length=128)

tokenized_datasets = dataset.map(tokenize_function)
split = tokenized_datasets.train_test_split(test_size=0.2)
train_dataset = split["train"]
test_dataset = split["test"]

#Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average="macro")
    acc = accuracy_score(labels, predictions)
    return {"accuracy": acc, "precision": precision, "recall": recall, "f1": f1}

#Custom trainers with weights
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")
        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)
        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))
        return (loss, outputs) if return_outputs else loss

#Trainer arguments
training_args = TrainingArguments(
    output_dir="./results",
    do_train=True,
    do_eval=True,
    save_steps=500,
    eval_steps=500,
    logging_steps=500,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    gradient_accumulation_steps=2,
    report_to="none"
)

#Train
trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)

trainer.train()

#Evaluation
print("Evaluation metrics:")
metrics = trainer.evaluate()
print(metrics)

#Classification Report
preds = trainer.predict(test_dataset)
y_true = preds.label_ids
y_pred = np.argmax(preds.predictions, axis=1)
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=[id2label[i] for i in range(len(id2label))], digits=4))

#F1-score and visual
report = classification_report(y_true, y_pred, target_names=[id2label[i] for i in range(len(id2label))], output_dict=True)
f1_scores = [report[label]["f1-score"] for label in report if label in id2label.values()]

plt.figure(figsize=(12, 6))
bars = plt.bar(id2label.values(), f1_scores, color="skyblue")
plt.ylim(0, 1)
plt.ylabel("F1-score")
plt.title("F1-score by Class (ToxiGen Classification)")
plt.xticks(rotation=45, ha="right")

for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f"{yval:.2f}", ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.show()

!pip install torch numpy datasets transformers scikit-learn

!pip install torch numpy datasets transformers scikit-learn

!pip install torch numpy datasets transformers scikit-learn

#Model 5
import torch
import numpy as np
import pandas as pd
from datasets import Dataset
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments
from transformers import Trainer

#Options
model_name = "microsoft/deberta-v3-small"
tokenizer = AutoTokenizer.from_pretrained(model_name)

#Load and data preparation
df = pd.read_csv("toxigen.csv")
df = df[df["prompt_label"] == 1].reset_index(drop=True)
df = df.rename(columns={"group": "label"})
labels = sorted(df.label.unique())
label2id = {label: idx for idx, label in enumerate(labels)}
id2label = {idx: label for label, idx in label2id.items()}
df["label"] = df["label"].map(label2id)

def tokenize(batch):
    return tokenizer(batch["generation"], truncation=True, padding="max_length", max_length=96)  # —Å–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏

#Test dataset
splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, test_idx = next(splitter.split(df["generation"], df["label"]))
test_df = df.iloc[test_idx].reset_index(drop=True)
test_dataset = Dataset.from_pandas(test_df)
test_dataset = test_dataset.map(tokenize)
test_dataset = test_dataset.remove_columns(["generation"])
y_true = test_df["label"].values

#Train args
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=24,
    per_device_eval_batch_size=64,
    num_train_epochs=2.5,
    logging_dir="./logs",
    save_strategy="no",
    eval_strategy="no",
    logging_steps=1000,
    report_to="none",
    fp16=torch.cuda.is_available(),
    gradient_accumulation_steps=1
)

#Custom Trainer w/ CrossEntropy
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits
        loss_fct = torch.nn.CrossEntropyLoss()
        loss = loss_fct(logits, labels)
        return (loss, outputs) if return_outputs else loss

#Train func for one model
def train_model(seed):
    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)
    train_idx, _ = next(split.split(df["generation"], df["label"]))
    train_df = df.iloc[train_idx].reset_index(drop=True)

    train_dataset = Dataset.from_pandas(train_df)
    train_dataset = train_dataset.map(tokenize)
    train_dataset = train_dataset.remove_columns(["generation"])

    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))
    trainer = CustomTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        tokenizer=tokenizer,
    )
    trainer.train()
    preds = trainer.predict(test_dataset).predictions
    return preds

#3 models train
preds1 = train_model(seed=101)
preds2 = train_model(seed=202)
preds3 = train_model(seed=303)

#Ensamble soft voting
ensemble_logits = (preds1 + preds2 + preds3) / 3
ensemble_preds = np.argmax(ensemble_logits, axis=1)

#Metrics
print("\nüìä Ensemble Classification Report:")
print(classification_report(
    y_true,
    ensemble_preds,
    target_names=[id2label[i] for i in range(len(id2label))],
    digits=4
))

#F1 visual
report = classification_report(
    y_true,
    ensemble_preds,
    target_names=[id2label[i] for i in range(len(id2label))],
    output_dict=True
)
f1_scores = [report[label]["f1-score"] for label in id2label.values()]

plt.figure(figsize=(12, 6))
bars = plt.bar(id2label.values(), f1_scores, color="coral")
plt.ylim(0, 1)
plt.ylabel("F1-score (Ensemble)")
plt.title("F1-score by Class (Soft Voting Ensemble)")
plt.xticks(rotation=45, ha="right")
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f"{yval:.2f}", ha='center', va='bottom', fontsize=9)
plt.tight_layout()
plt.show()

#Model 4
import torch
import pandas as pd
import numpy as np
from datasets import Dataset, ClassLabel
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, DataCollatorWithPadding, DebertaV2Config
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
from random import random, choice
import matplotlib.pyplot as plt
import seaborn as sns
import time

torch.backends.cudnn.benchmark = True


#Data load
df = pd.read_csv("toxigen.csv")
df = df[df["prompt_label"] == 1].reset_index(drop=True)
df["text_processed"] = df["generation"].str.lower().str.strip()
df["input_text"] = df["text_processed"]
df.drop(columns=["roberta_prediction"], inplace=True)

labels = df["group"].unique().tolist()
label2id = {label: i for i, label in enumerate(labels)}
df["label"] = df["group"].map(label2id)

#Stratification
train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df["label"], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df["label"], random_state=42)

#Dataset
train_dataset = Dataset.from_pandas(train_df).cast_column("label", ClassLabel(names=labels))
val_dataset = Dataset.from_pandas(val_df).cast_column("label", ClassLabel(names=labels))
test_dataset = Dataset.from_pandas(test_df).cast_column("label", ClassLabel(names=labels))

#Tokenizer and model
model_name = "microsoft/deberta-v3-large"
tokenizer = AutoTokenizer.from_pretrained(model_name)
config = DebertaV2Config.from_pretrained(
    model_name,
    num_labels=len(labels),
    hidden_dropout_prob=0.3,
    id2label={i: label for i, label in enumerate(labels)},
    label2id=label2id
)
model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config).to("cuda")

#Augmentation of weak classes
weak_classes = ["latino", "jewish", "native_american"]

def augment_example(example):
    text = example["input_text"]
    label = example["label"]
    if labels[label] in weak_classes and random() < 0.3:
        words = text.split()
        if len(words) > 5:
            idx = choice(range(len(words)))
            words[idx] = "[MASK]"
            example["input_text"] = " ".join(words)
    return example

train_dataset = train_dataset.map(augment_example)

#Token
def tokenize_function(example):
    return tokenizer(example["input_text"], truncation=True, max_length=256)

keep_cols = ["label", "input_ids", "attention_mask", "token_type_ids"]
train_dataset = train_dataset.map(tokenize_function, batched=True).remove_columns([col for col in train_dataset.column_names if col not in keep_cols])
val_dataset = val_dataset.map(tokenize_function, batched=True).remove_columns([col for col in val_dataset.column_names if col not in keep_cols])
test_dataset = test_dataset.map(tokenize_function, batched=True).remove_columns([col for col in test_dataset.column_names if col not in keep_cols])

#mETRICS
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    accuracy = accuracy_score(labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average="macro", zero_division=0)
    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}

#Class weights
class_weights = compute_class_weight("balanced", classes=np.arange(len(labels)), y=train_df["label"])
class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to("cuda")

#Focal Loss
class FocalLoss(torch.nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)
        pt = torch.exp(-ce_loss)
        focal_loss = ((1 - pt) ** self.gamma) * ce_loss
        return focal_loss.mean() if self.reduction == 'mean' else focal_loss

#Custom Trainer
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits
        loss_fct = FocalLoss(alpha=class_weights_tensor, gamma=2.0)
        loss = loss_fct(logits, labels)
        return (loss, outputs) if return_outputs else loss

#Trainer arguments
training_args = TrainingArguments(
    output_dir="./results_deberta",
    eval_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=6,
    gradient_accumulation_steps=4,
    num_train_epochs=2,
    weight_decay=0.01,
    fp16=True,
    learning_rate=1e-5,
    lr_scheduler_type="cosine",
    warmup_ratio=0.1,
    optim="adamw_torch",
    report_to="none",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    logging_steps=100,
    dataloader_num_workers=4,
)

callbacks = [EarlyStoppingCallback(early_stopping_patience=1)]

trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=callbacks,
    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)
)

#Train
trainer.train()

#Evaluation
metrics = trainer.evaluate(test_dataset)
print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:", metrics)

# Classification report + F1
predictions = trainer.predict(test_dataset)
y_pred = np.argmax(predictions.predictions, axis=-1)
y_true = predictions.label_ids

report = classification_report(y_true, y_pred, target_names=labels, digits=4, output_dict=True)
print("\nF1 –ø–æ –∫–ª–∞—Å—Å–∞–º:")
for label in labels:
    print(f"{label}: F1 = {report[label]['f1-score']:.4f}")

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=labels, digits=4))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
fig, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels, cbar=False, linewidths=0.5)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.xticks(rotation=45, ha="right")
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

#F1 visualisation
f1_scores = [report[label]["f1-score"] for label in labels]
plt.figure(figsize=(12, 6))
sns.barplot(x=labels, y=f1_scores, color="skyblue")
plt.title("F1 Score per Class")
plt.ylabel("F1 Score")
plt.xticks(rotation=45, ha="right")
plt.ylim(0, 1)
plt.tight_layout()
plt.show()